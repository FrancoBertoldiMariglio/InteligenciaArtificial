{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:55:46.384523Z",
     "start_time": "2024-10-08T21:55:46.380360Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Asignamos el dataset a la variable **dataset**"
   ],
   "metadata": {
    "id": "_1gUgAWK1Rqf"
   },
   "id": "_1gUgAWK1Rqf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cats_vs_dogs\")"
   ],
   "metadata": {
    "id": "62a3f5b0b4d5fd4e",
    "outputId": "1ebc66c6-45c8-4233-e516-8cbcc83f25f6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-10-08T21:55:50.001781Z",
     "start_time": "2024-10-08T21:55:46.464413Z"
    }
   },
   "id": "62a3f5b0b4d5fd4e",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos un *DataFrame* llamado **mydataset**, el cual almacenará el path de cada imagen junto a su etiqueta (perro o gato). Además creamos un directorio llamado dataset y almacenamos allí las imágenes.\n"
   ],
   "metadata": {
    "id": "jiS_pLhO1hIe"
   },
   "id": "jiS_pLhO1hIe"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             image_path label\n0  ./dataset/img_0.jpeg     0\n1  ./dataset/img_1.jpeg     0\n2  ./dataset/img_2.jpeg     0\n3  ./dataset/img_3.jpeg     0\n4  ./dataset/img_4.jpeg     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./dataset/img_0.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./dataset/img_1.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./dataset/img_2.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./dataset/img_3.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./dataset/img_4.jpeg</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dir = './dataset'\n",
    "os.makedirs(main_dir, exist_ok=True)\n",
    "\n",
    "mydataset = pd.DataFrame(columns=['image_path', 'label'])\n",
    "\n",
    "for i in range(len(dataset['train'])):\n",
    "    img_path = f\"{main_dir}/img_{i}.jpeg\"\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        dataset['train'][i]['image'].save(img_path)\n",
    "\n",
    "    mydataset.at[i, 'image_path'] = img_path\n",
    "    mydataset.at[i, 'label'] = dataset['train'][i]['labels']\n",
    "\n",
    "mydataset.head()"
   ],
   "metadata": {
    "id": "18f786f3d1d77ead",
    "outputId": "d6c1ad40-931c-4568-91dd-10b119ca645d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.185055Z",
     "start_time": "2024-10-08T21:55:50.003066Z"
    }
   },
   "id": "18f786f3d1d77ead",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definimos la semilla para que al divir el dataset en trainn y test, sea la misma división de datos. Por otro lado, creamos un diccionario para almacenar los parámetros que usaremos. Además, especificamos la proporción de datos que serán para testeo y para validación.\n",
    "\n",
    "> **Aclaración:** los datos de validación surgen de una proporción sobre los datos de testeo.\n",
    "\n"
   ],
   "metadata": {
    "id": "VKScy5ZE1_KS"
   },
   "id": "VKScy5ZE1_KS"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seed = 42\n",
    "test_size = 0.15\n",
    "val_size = 0.20\n",
    "\n",
    "exp_config = dict()\n",
    "exp_config['seed'] = seed\n",
    "exp_config['test_size'] = test_size\n",
    "exp_config['val_size'] = val_size"
   ],
   "metadata": {
    "id": "5ae023464ee7d8ff",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.187799Z",
     "start_time": "2024-10-08T21:56:12.185781Z"
    }
   },
   "id": "5ae023464ee7d8ff",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dividimos el dataset en *train*, *test*, *val*.\n"
   ],
   "metadata": {
    "id": "wSXflM8R23IA"
   },
   "id": "wSXflM8R23IA"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_val_df, test_df = train_test_split(mydataset, test_size=test_size, stratify=mydataset['label'], random_state=seed)\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size, stratify=train_val_df['label'], random_state=seed)"
   ],
   "metadata": {
    "id": "acfdebddb8975812",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.213106Z",
     "start_time": "2024-10-08T21:56:12.189617Z"
    }
   },
   "id": "acfdebddb8975812",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Añadimos parámetros de configuración al diccionario."
   ],
   "metadata": {
    "id": "ZZKi7exX3C1O"
   },
   "id": "ZZKi7exX3C1O"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exp_config['train_n_cats'] = train_df['label'].value_counts()[0]\n",
    "exp_config['train_n_dogs'] = train_df['label'].value_counts()[1]\n",
    "exp_config['val_n_cats'] = val_df['label'].value_counts()[0]\n",
    "exp_config['val_n_dogs'] = val_df['label'].value_counts()[1]\n",
    "exp_config['test_n_cats'] = test_df['label'].value_counts()[0]\n",
    "exp_config['test_n_dogs'] = test_df['label'].value_counts()[1]"
   ],
   "metadata": {
    "id": "917c26bc02be395f",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.221819Z",
     "start_time": "2024-10-08T21:56:12.214221Z"
    }
   },
   "id": "917c26bc02be395f",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "La clase CatsDogsDataset es una implementación personalizada de un conjunto de datos para un programa de visión por computadora que clasifica imágenes de gatos y perros\n",
    "\n",
    "**Explicación**\n",
    "1. Constructor (__init__):  \n",
    "- img_path_list: Lista de rutas de las imágenes.\n",
    "- lab_list: Lista de etiquetas correspondientes a las imágenes (0 para gatos, 1 para perros).\n",
    "- transform: Transformaciones opcionales que se aplicarán a las imágenes (por ejemplo, redimensionar, normalizar).\n",
    "2. Método __len__:  \n",
    "- Devuelve la cantidad de imágenes en el conjunto de datos.\n",
    "3. Método __getitem__:\n",
    "- idx: Índice de la imagen y etiqueta que se desea obtener.\n",
    "- img_path: Obtiene la ruta de la imagen en el índice idx.\n",
    "- image: Abre la imagen y la convierte a formato RGB.\n",
    "- label: Obtiene la etiqueta correspondiente a la imagen y la convierte a un tensor de PyTorch.\n",
    "- Si se especificaron transformaciones, se aplican a la imagen.\n",
    "- Devuelve la imagen transformada y su etiqueta correspondiente."
   ],
   "metadata": {
    "id": "c-1bZ5CU3Gri"
   },
   "id": "c-1bZ5CU3Gri"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CatsDogsDataset(Dataset):\n",
    "    def __init__(self, img_path_list, lab_list, transform=None):\n",
    "        self.transform = transform\n",
    "        self.images = img_path_list\n",
    "        self.labels = lab_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        label = torch.Tensor([label])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "id": "2cd7f71cfa333705",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.225379Z",
     "start_time": "2024-10-08T21:56:12.222785Z"
    }
   },
   "id": "2cd7f71cfa333705",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definimos la resolución de las imágenes que serán procesadas."
   ],
   "metadata": {
    "id": "mNXY7zTh31QJ"
   },
   "id": "mNXY7zTh31QJ"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_size = (224,224)\n",
    "exp_config['input_size'] = input_size"
   ],
   "metadata": {
    "id": "61b41a6d728d3c10",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.228174Z",
     "start_time": "2024-10-08T21:56:12.226279Z"
    }
   },
   "id": "61b41a6d728d3c10",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como las imágenes son a color en formato RGB, definiremos 3 canales"
   ],
   "metadata": {
    "id": "fBTkFhnn382u"
   },
   "id": "fBTkFhnn382u"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_channels = 3\n",
    "exp_config['n_channels'] = n_channels"
   ],
   "metadata": {
    "id": "7e9634b1fc3514d6",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.231614Z",
     "start_time": "2024-10-08T21:56:12.229064Z"
    }
   },
   "id": "7e9634b1fc3514d6",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos el *transformador* que será usado, el cual redimensiona las imágenes a la resolución dada."
   ],
   "metadata": {
    "id": "qb6wxASF4KHR"
   },
   "id": "qb6wxASF4KHR"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ],
   "metadata": {
    "id": "60979fd3aadf9c30",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.237336Z",
     "start_time": "2024-10-08T21:56:12.232757Z"
    }
   },
   "id": "60979fd3aadf9c30",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos los datasets de\n",
    "- Train\n",
    "- Test\n",
    "- Val\n",
    "\n",
    "> **Aclaración:** son creados a partir de la clase CatsDogsDataset y usan como parámetro el *transformer* definido previamente.\n"
   ],
   "metadata": {
    "id": "j-RUgCbO4Yg_"
   },
   "id": "j-RUgCbO4Yg_"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CatsDogsDataset(train_df['image_path'].tolist(), train_df['label'].tolist(), transform)\n",
    "val_dataset = CatsDogsDataset(val_df['image_path'].tolist(), val_df['label'].tolist(), transform)\n",
    "test_dataset = CatsDogsDataset(test_df['image_path'].tolist(), test_df['label'].tolist(), transform)"
   ],
   "metadata": {
    "id": "5adde669c2867e8d",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.243143Z",
     "start_time": "2024-10-08T21:56:12.240214Z"
    }
   },
   "id": "5adde669c2867e8d",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos los *dataloaders* de train, val y test y definimos el tamaño de lote.\n",
    "\n",
    "> **Aclaración:** el batch size de test es 1 y además los datos no serán mezclados por cada épocas y no se eliminarán datos para alcanzar el tamaño de lote establecido."
   ],
   "metadata": {
    "id": "CzsTv8jC4-Js"
   },
   "id": "CzsTv8jC4-Js"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "exp_config['batch_size'] = batch_size\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ],
   "metadata": {
    "id": "cc5bed8c2518e66c",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.248086Z",
     "start_time": "2024-10-08T21:56:12.243924Z"
    }
   },
   "id": "cc5bed8c2518e66c",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelos\n",
    "\n",
    "Definimos 2 modelos, uno hecho *from scratch* y otro en base a *ResNet18*.\n"
   ],
   "metadata": {
    "id": "FFrM1a1R94KL"
   },
   "id": "FFrM1a1R94KL"
  },
  {
   "cell_type": "code",
   "source": [
    "#Definición de mi red\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # Capa convolucional\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)        # Max pooling\n",
    "        self.relu = nn.ReLU()                                    # Activación ReLu no lineal\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # Otra capa convolucional\n",
    "        self.flatten = nn.Flatten()                              # Capa flatten\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 64)                   # Capa completamente conectada (el calculo del primer parámetro depende de dim entrada y capas previas)\n",
    "        self.fc2 = nn.Linear(64, 1)                              # Capa de salida para clasificación binaria (1 neurona + Act. Sigmoide)\n",
    "        self.sigmoid = nn.Sigmoid()                              # Activación sigmoide\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.conv1(x)     #(E: Nx3x224x224 -> S:NX16x224x224)\n",
    "      x = self.relu(x)      #\n",
    "      x = self.pool(x)      # (->S: Nx16x112x112)\n",
    "\n",
    "      x = self.conv2(x)     # (->S: Nx32x112x112)\n",
    "      x = self.relu(x)      #\n",
    "      x = self.pool(x)      #  (->S: Nx32x56x56)\n",
    "\n",
    "      x = self.flatten(x)   # -> S: 32×56×56=100352\n",
    "      x = self.fc1(x)       # -> S: 64\n",
    "      x = self.relu(x)      #\n",
    "      x = self.fc2(x)       # -> S: 1\n",
    "      x = torch.sigmoid(x)  #\n",
    "\n",
    "      return x"
   ],
   "metadata": {
    "id": "JZ9_Zdd36fpA",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.253888Z",
     "start_time": "2024-10-08T21:56:12.248848Z"
    }
   },
   "id": "JZ9_Zdd36fpA",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)  # Cargar ResNet18 preentrenada\n",
    "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, 1)  # Modificar la capa de salida\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = torch.sigmoid (x) # Activación sigmoide en la salida (otra manera de aplicarla)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "id": "8b08e7104cfe584d",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.257797Z",
     "start_time": "2024-10-08T21:56:12.255048Z"
    }
   },
   "id": "8b08e7104cfe584d",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrenamiento\n"
   ],
   "metadata": {
    "id": "-ei2LSA391BP"
   },
   "id": "-ei2LSA391BP"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.name == 'posix':\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "elif os.name == 'nt':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "device"
   ],
   "metadata": {
    "id": "a50750bcf13f5bf7",
    "outputId": "07dbdb3d-40ac-444c-ade6-b28c98b11f0e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.309337Z",
     "start_time": "2024-10-08T21:56:12.258897Z"
    }
   },
   "id": "a50750bcf13f5bf7",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elección de modelo, función de costo y optimizador."
   ],
   "metadata": {
    "id": "xXc3QO35-Gt0"
   },
   "id": "xXc3QO35-Gt0"
  },
  {
   "cell_type": "code",
   "source": [
    "model = SimpleCNN().to(device)\n",
    "exp_config['model'] = 'SimpleCNN'\n",
    "criterion = nn.BCELoss() #BinaryCrossEntropy o Entropía Cruzada Binaria\n",
    "exp_config['model'] = 'BCELoss'\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr) #Importante pasarle los parámetros del modelo al optimizador !\n",
    "exp_config['optimizador'] = 'Adam'\n",
    "exp_config['learning_rate'] = lr"
   ],
   "metadata": {
    "id": "VjEFHNvs-Mvh",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.432832Z",
     "start_time": "2024-10-08T21:56:12.310012Z"
    }
   },
   "id": "VjEFHNvs-Mvh",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parámetros seleccionados hasta el momento."
   ],
   "metadata": {
    "id": "Boj5ugd5-b_Q"
   },
   "id": "Boj5ugd5-b_Q"
  },
  {
   "cell_type": "code",
   "source": [
    "exp_config"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XYlYUo4-ZPF",
    "outputId": "af63fb36-a1ab-47d4-caf2-ff50f4725409",
    "ExecuteTime": {
     "end_time": "2024-10-08T21:56:12.436854Z",
     "start_time": "2024-10-08T21:56:12.433573Z"
    }
   },
   "id": "7XYlYUo4-ZPF",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'seed': 42,\n 'test_size': 0.15,\n 'val_size': 0.2,\n 'train_n_cats': 7984,\n 'train_n_dogs': 7934,\n 'val_n_cats': 1996,\n 'val_n_dogs': 1984,\n 'test_n_cats': 1761,\n 'test_n_dogs': 1751,\n 'input_size': (224, 224),\n 'n_channels': 3,\n 'batch_size': 64,\n 'model': 'BCELoss',\n 'optimizador': 'Adam',\n 'learning_rate': 0.001}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Función de entrenamiento y validación."
   ],
   "metadata": {
    "id": "LFqvj0Hz-fXq"
   },
   "id": "LFqvj0Hz-fXq"
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, train_dataloader, criterion, optimizer, device):\n",
    "\n",
    "    model.to(device) #Enviar el modelo al dispositivo\n",
    "    model.train()  # Configurar el modelo en modo de entrenamiento\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Enviar los datos al dispositivo\n",
    "\n",
    "        optimizer.zero_grad()  # Reiniciar los gradientes\n",
    "        outputs = model(images)  # Forward pass\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Calcular la pérdida\n",
    "        loss.backward()  # Backward pass\n",
    "\n",
    "        optimizer.step()  # Actualizar parámetros\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calcular exactitud\n",
    "        threshold = 0.5  # Umbral para clasificar\n",
    "        predicted = (outputs.detach() >= threshold)  # 1 si >= umbral, 0 si < umbral\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_avg_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    return train_avg_loss, train_accuracy\n",
    "\n",
    "def validate(model, val_dataloader, criterion, device):\n",
    "\n",
    "    model.eval()  # Configurar el modelo en modo de evaluación\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Desactivar gradientes\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calcular precisión\n",
    "            threshold = 0.5  # Umbral para clasificar\n",
    "            predicted = (outputs.detach() >= threshold)  # 1 si >= umbral, 0 si < umbral\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_avg_loss = running_loss / len(val_dataloader)\n",
    "    val_accuracy = correct / total\n",
    "    \n",
    "    return val_avg_loss, val_accuracy\n"
   ],
   "metadata": {
    "id": "C7hXPmvE-kMD",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:01:46.568925Z",
     "start_time": "2024-10-08T22:01:46.563654Z"
    }
   },
   "id": "C7hXPmvE-kMD",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## WandB"
   ],
   "metadata": {
    "id": "EIOjZvGA-7hH"
   },
   "id": "EIOjZvGA-7hH"
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.login(key=\"d567fa512c6502cc7986d8c90fd37c4f0969de0d\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdsh8Yex_rmJ",
    "outputId": "44c3f939-891e-4c3e-f5fb-c3df65879a3e",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:01:49.408234Z",
     "start_time": "2024-10-08T22:01:48.923731Z"
    }
   },
   "id": "xdsh8Yex_rmJ",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mintart-estudiantes\u001B[0m (\u001B[33mar-um\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /Users/francobertoldi/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#wandb.init(project=\"CNN_CatsvsDogs\", entity=\"ar-um\", tags = [\"BERTOLDI_MANCUSO\"])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385,
     "referenced_widgets": [
      "4188ce01866d421a88a899a6d5aa0759",
      "6fa6a1fe26774229babc0645dbcd144c",
      "985961fe655c4f47819b89934ea044c4",
      "7bf789691c6b486fa4e927ad3572c931",
      "7e32cbed945347619688e6f7847dfc8c",
      "6ab2e4d5660448209365eb8170c4733b",
      "73e22c85b6514fadbc6b917bb81f29ec",
      "8632914e59cc4b80bf18e7ff63c4728f"
     ]
    },
    "id": "cKZ5JoW7_pEy",
    "outputId": "8ec942d3-cf96-4331-aef8-dd8bb87daddc",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:01:49.972208Z",
     "start_time": "2024-10-08T22:01:49.970348Z"
    }
   },
   "id": "cKZ5JoW7_pEy",
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#wandb.config.update(exp_config)"
   ],
   "metadata": {
    "id": "T5iv72kl_3i1",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:01:50.530652Z",
     "start_time": "2024-10-08T22:01:50.527938Z"
    }
   },
   "id": "T5iv72kl_3i1",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ajuste del modelo"
   ],
   "metadata": {
    "id": "V7EN1hNM-vUA"
   },
   "id": "V7EN1hNM-vUA"
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 15\n",
    "early_stopping_patience = 5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "exp_config['num_epochs'] = num_epochs\n",
    "exp_config['early_stopping_patience'] = early_stopping_patience\n",
    "\n",
    "checkpoint_path = './best_model.pth'\n",
    "\n",
    "best_val_loss = float('inf')  # Inicializa con infinito positivo\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(model, train_dataloader, criterion, optimizer, device)\n",
    "    val_loss, val_accuracy = validate(model, val_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}, '\n",
    "          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "    #Registro de metricas en WandB\n",
    "    # wandb.log({\"epochs\": epoch,\n",
    "    #           \"train_acc\": train_accuracy,\n",
    "    #            \"train_loss\": train_loss,\n",
    "    #            \"val_acc\": val_accuracy,\n",
    "    #            \"val_loss\": val_loss})\n",
    "\n",
    "    #Checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "      best_val_loss = val_loss #actualizo el valor de la mejor (menor) loss\n",
    "      torch.save(model.state_dict(), checkpoint_path) #almaceno el mejor modelo\n",
    "      epochs_without_improvement = 0 #reinicio este contador\n",
    "      print(\"Checkpoint saved\")\n",
    "\n",
    "    #Early Stopping\n",
    "    else:\n",
    "      epochs_without_improvement +=1\n",
    "      if epochs_without_improvement == early_stopping_patience:\n",
    "        print(\"Early Stopping\")\n",
    "        break #Interrumpo el entrenamiento\n",
    "\n",
    "#wandb.finish() No lo vamos a frenar acá para poder registrar los resultados en test"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "WuTBZ-ZU-x_a",
    "outputId": "73c7afc0-ec74-40cc-ed9c-b79203f672bc",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:21:32.607367Z",
     "start_time": "2024-10-08T22:01:51.850361Z"
    }
   },
   "id": "WuTBZ-ZU-x_a",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.4095, Train Accuracy: 0.81, Validation Loss: 0.3217, Validation Accuracy: 0.87\n",
      "Checkpoint saved\n",
      "Epoch [2/15], Train Loss: 0.3205, Train Accuracy: 0.86, Validation Loss: 0.2375, Validation Accuracy: 0.90\n",
      "Checkpoint saved\n",
      "Epoch [3/15], Train Loss: 0.2226, Train Accuracy: 0.91, Validation Loss: 0.1517, Validation Accuracy: 0.95\n",
      "Checkpoint saved\n",
      "Epoch [4/15], Train Loss: 0.1297, Train Accuracy: 0.95, Validation Loss: 0.0695, Validation Accuracy: 0.98\n",
      "Checkpoint saved\n",
      "Epoch [5/15], Train Loss: 0.0626, Train Accuracy: 0.98, Validation Loss: 0.0337, Validation Accuracy: 0.99\n",
      "Checkpoint saved\n",
      "Epoch [6/15], Train Loss: 0.0366, Train Accuracy: 0.99, Validation Loss: 0.0264, Validation Accuracy: 0.99\n",
      "Checkpoint saved\n",
      "Epoch [7/15], Train Loss: 0.0196, Train Accuracy: 1.00, Validation Loss: 0.0227, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [8/15], Train Loss: 0.0214, Train Accuracy: 0.99, Validation Loss: 0.0110, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [9/15], Train Loss: 0.0189, Train Accuracy: 0.99, Validation Loss: 0.0199, Validation Accuracy: 0.99\n",
      "Epoch [10/15], Train Loss: 0.0187, Train Accuracy: 0.99, Validation Loss: 0.0094, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [11/15], Train Loss: 0.0074, Train Accuracy: 1.00, Validation Loss: 0.0064, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [12/15], Train Loss: 0.0047, Train Accuracy: 1.00, Validation Loss: 0.0014, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [13/15], Train Loss: 0.0141, Train Accuracy: 1.00, Validation Loss: 0.0757, Validation Accuracy: 0.97\n",
      "Epoch [14/15], Train Loss: 0.0352, Train Accuracy: 0.99, Validation Loss: 0.0082, Validation Accuracy: 1.00\n",
      "Epoch [15/15], Train Loss: 0.0160, Train Accuracy: 0.99, Validation Loss: 0.0079, Validation Accuracy: 1.00\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testeo"
   ],
   "metadata": {
    "id": "s-i41uMIBX3Y"
   },
   "id": "s-i41uMIBX3Y"
  },
  {
   "cell_type": "code",
   "source": [
    "#model = SimpleCNN()  # Reemplaza con la clase de tu modelo\n",
    "#model = ResNet18()\n",
    "model #si se hace todo en una sola corrida, basta con usar el modelo que ya esta instanciado y cargar los pesos\n",
    "\n",
    "#Cargar los pesos del checkpoint\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.to(device)\n",
    "\n",
    "# Establece el modelo en modo evaluación\n",
    "model.eval()"
   ],
   "metadata": {
    "id": "lWdHrwGE-0QP",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:21:40.276957Z",
     "start_time": "2024-10-08T22:21:40.227146Z"
    }
   },
   "id": "lWdHrwGE-0QP",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/8g60y89560j6qzlm3sgc1_jh0000gn/T/ipykernel_13443/2667991869.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": "SimpleCNN(\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (relu): ReLU()\n  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (fc1): Linear(in_features=100352, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=1, bias=True)\n  (sigmoid): Sigmoid()\n)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_proba = []\n",
    "\n",
    "# Iterar sobre el conjunto de prueba\n",
    "for image, label in test_dataloader:\n",
    "    image, label = image.to(device), label.to(device)  # Enviar los datos al dispositivo\n",
    "\n",
    "    with torch.no_grad():  # Desactivar el cálculo de gradientes\n",
    "        output = model(image)  # Realizar la inferencia\n",
    "\n",
    "        y_true.append(label.to(\"cpu\").float())  # Guardar los labels como tensores de PyTorch\n",
    "        y_proba.append(output.to(\"cpu\").float())  # Guardar las probabilidades como tensores de PyTorch\n"
   ],
   "metadata": {
    "id": "D6iOBHPNBcYt",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:37:01.370329Z",
     "start_time": "2024-10-08T22:36:47.371750Z"
    }
   },
   "id": "D6iOBHPNBcYt",
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[1.]]),\n tensor([[0.]]),\n tensor([[0.]]),\n ...]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T22:37:03.775152Z",
     "start_time": "2024-10-08T22:37:03.713303Z"
    }
   },
   "id": "e92cf7cb3fe4058b",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "source": [
    "# Definimos el umbral arbitrario\n",
    "thr = 0.5\n",
    "\n",
    "# Convertir las listas de tensores a un solo tensor\n",
    "y_true_tensor = torch.cat(y_true)  # Concatenar todos los tensores de labels\n",
    "y_proba_tensor = torch.cat(y_proba)  # Concatenar todos los tensores de probabilidades\n",
    "\n",
    "# Aplicar el umbral y obtener las predicciones binarias\n",
    "y_pred_tensor = (y_proba_tensor >= thr).int()\n",
    "\n",
    "# Convertir a NumPy arrays al final\n",
    "y_true = y_true_tensor.numpy()\n",
    "y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "# Ahora y_pred debería tener la misma forma que y_true\n",
    "print(y_true.shape, y_pred.shape)"
   ],
   "metadata": {
    "id": "7OUK486cBhx9",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:37:06.832268Z",
     "start_time": "2024-10-08T22:37:06.829041Z"
    }
   },
   "id": "7OUK486cBhx9",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3512, 1) (3512, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, precision_score, recall_score\n",
    "\n",
    "# Calcular métricas de clasificación\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "# Calcular la curva ROC\n",
    "# fpr, tpr, _ = roc_curve(y_true, y_proba)  # y_pred_proba es la probabilidad predicha\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ],
   "metadata": {
    "id": "r2Bm6XvEBi6I",
    "ExecuteTime": {
     "end_time": "2024-10-08T22:40:29.422434Z",
     "start_time": "2024-10-08T22:40:29.406252Z"
    }
   },
   "id": "r2Bm6XvEBi6I",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Precision: 0.75\n",
      "Recall: 0.74\n",
      "Specificity: 0.75\n",
      "Confusion Matrix:\n",
      "[[1317  444]\n",
      " [ 451 1300]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d9c29b5bb1385104"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4188ce01866d421a88a899a6d5aa0759": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6fa6a1fe26774229babc0645dbcd144c",
       "IPY_MODEL_985961fe655c4f47819b89934ea044c4"
      ],
      "layout": "IPY_MODEL_7bf789691c6b486fa4e927ad3572c931"
     }
    },
    "6fa6a1fe26774229babc0645dbcd144c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e32cbed945347619688e6f7847dfc8c",
      "placeholder": "​",
      "style": "IPY_MODEL_6ab2e4d5660448209365eb8170c4733b",
      "value": "0.011 MB of 0.011 MB uploaded\r"
     }
    },
    "985961fe655c4f47819b89934ea044c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73e22c85b6514fadbc6b917bb81f29ec",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8632914e59cc4b80bf18e7ff63c4728f",
      "value": 1
     }
    },
    "7bf789691c6b486fa4e927ad3572c931": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e32cbed945347619688e6f7847dfc8c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ab2e4d5660448209365eb8170c4733b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73e22c85b6514fadbc6b917bb81f29ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8632914e59cc4b80bf18e7ff63c4728f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
