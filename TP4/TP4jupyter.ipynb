{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Trabajo Pracatico 4 - Redes Neuronales Convolucionales\n",
    "\n",
    "Vamos a realizar una clasificacion binaria de imagnes que pueden ser de gatos o perros, para ello vamos a utilizar un dataset de Kaggle llamado \"cats-vs-dogs\" que contiene 23.409 imágenes de gatos y perros. El objetivo es entrenar un modelo de clasificación binaria que pueda distinguir entre imágenes de gatos y perros.\n",
    "\n",
    "Se van a proponer los siguientes modelos:\n",
    "\n",
    "- **Modelo 1:** Red convolucional simple (SimpleCNN) creada desde cero.\n",
    "- **Modelo 2:** Red convolucional basada en ResNet18.\n",
    "- **Modelo 4:** Red convolucional avanzacda (AdvancedCNN) creada desde cero.\n",
    "- **Modelo 3:** Red convolucional basada en ResNet18 con cambios en hiperparametros.\n",
    "- **Modelo 5:** Red convolucional basada en Inception de Google con cambios en hiperparametros."
   ],
   "metadata": {
    "collapsed": false,
    "id": "5aa4d9bed7ac6d10"
   },
   "id": "5aa4d9bed7ac6d10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Asignamos el dataset a la variable **dataset**"
   ],
   "metadata": {
    "id": "_1gUgAWK1Rqf"
   },
   "id": "_1gUgAWK1Rqf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.16.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.14.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cats_vs_dogs\")"
   ],
   "metadata": {
    "id": "62a3f5b0b4d5fd4e",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:11:46.969657Z",
     "start_time": "2024-10-14T03:10:22.438371Z"
    },
    "outputId": "15f9cbac-d21c-42b2-b66f-c2e0559427bd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "62a3f5b0b4d5fd4e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos un *DataFrame* llamado **mydataset**, el cual almacenará el path de cada imágen junto a su etiqueta (perro o gato). Además creamos un directorio llamado dataset y almacenamos allí las imágenes.\n"
   ],
   "metadata": {
    "id": "jiS_pLhO1hIe"
   },
   "id": "jiS_pLhO1hIe"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             image_path label\n",
       "0  ./dataset/img_0.jpeg     0\n",
       "1  ./dataset/img_1.jpeg     0\n",
       "2  ./dataset/img_2.jpeg     0\n",
       "3  ./dataset/img_3.jpeg     0\n",
       "4  ./dataset/img_4.jpeg     0"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-5524af47-f4de-447b-ac08-1d6054c9b09d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/img_0.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/img_1.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/img_2.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/img_3.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/img_4.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5524af47-f4de-447b-ac08-1d6054c9b09d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5524af47-f4de-447b-ac08-1d6054c9b09d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5524af47-f4de-447b-ac08-1d6054c9b09d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a7f3b94b-3c2e-48b2-8200-a93cddfc5ec0\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7f3b94b-3c2e-48b2-8200-a93cddfc5ec0')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a7f3b94b-3c2e-48b2-8200-a93cddfc5ec0 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "mydataset",
       "summary": "{\n  \"name\": \"mydataset\",\n  \"rows\": 23410,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23410,\n        \"samples\": [\n          \"./dataset/img_9016.jpeg\",\n          \"./dataset/img_18648.jpeg\",\n          \"./dataset/img_10018.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "main_dir = './dataset'\n",
    "os.makedirs(main_dir, exist_ok=True)\n",
    "\n",
    "mydataset = pd.DataFrame(columns=['image_path', 'label'])\n",
    "\n",
    "for i in range(len(dataset['train'])):\n",
    "    img_path = f\"{main_dir}/img_{i}.jpeg\"\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        dataset['train'][i]['image'].save(img_path)\n",
    "\n",
    "    mydataset.at[i, 'image_path'] = img_path\n",
    "    mydataset.at[i, 'label'] = dataset['train'][i]['labels']\n",
    "\n",
    "mydataset.head()"
   ],
   "metadata": {
    "id": "18f786f3d1d77ead",
    "outputId": "dc442974-49e8-4411-f62a-1fb94012e8fc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.144279Z",
     "start_time": "2024-10-14T03:11:46.971265Z"
    }
   },
   "id": "18f786f3d1d77ead",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos un diccionario para almacenar los parámetros que usaremos."
   ],
   "metadata": {
    "collapsed": false,
    "id": "b74f536a3a8038ee"
   },
   "id": "b74f536a3a8038ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exp_config = dict()"
   ],
   "metadata": {
    "id": "efa97dd716f5447a",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.146618Z",
     "start_time": "2024-10-14T03:12:08.144958Z"
    }
   },
   "id": "efa97dd716f5447a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definimos la semilla para que al divir el dataset en train, test y val, sea siempre la misma división de datos. Además, especificamos la proporción de datos que serán para testeo y para validación."
   ],
   "metadata": {
    "id": "VKScy5ZE1_KS"
   },
   "id": "VKScy5ZE1_KS"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seed = 42\n",
    "test_size = 0.15\n",
    "val_size = 0.20\n",
    "\n",
    "exp_config['seed'] = seed\n",
    "exp_config['test_size'] = test_size\n",
    "exp_config['val_size'] = val_size"
   ],
   "metadata": {
    "id": "5ae023464ee7d8ff",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.149476Z",
     "start_time": "2024-10-14T03:12:08.147876Z"
    }
   },
   "id": "5ae023464ee7d8ff",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dividimos el dataset en *train*, *test*, *val*.\n",
    "\n",
    "**Aclaración:** los datos de validación surgen de una parte de los datos de testeo."
   ],
   "metadata": {
    "id": "wSXflM8R23IA"
   },
   "id": "wSXflM8R23IA"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_df, test_df = train_test_split(mydataset, test_size=test_size, stratify=mydataset['label'], random_state=seed)\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size, stratify=train_val_df['label'], random_state=seed)"
   ],
   "metadata": {
    "id": "acfdebddb8975812",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.171287Z",
     "start_time": "2024-10-14T03:12:08.150101Z"
    }
   },
   "id": "acfdebddb8975812",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Añadimos parámetros de configuración al diccionario."
   ],
   "metadata": {
    "id": "ZZKi7exX3C1O"
   },
   "id": "ZZKi7exX3C1O"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exp_config['train_n_cats'] = train_df['label'].value_counts()[0]\n",
    "exp_config['train_n_dogs'] = train_df['label'].value_counts()[1]\n",
    "exp_config['val_n_cats'] = val_df['label'].value_counts()[0]\n",
    "exp_config['val_n_dogs'] = val_df['label'].value_counts()[1]\n",
    "exp_config['test_n_cats'] = test_df['label'].value_counts()[0]\n",
    "exp_config['test_n_dogs'] = test_df['label'].value_counts()[1]"
   ],
   "metadata": {
    "id": "917c26bc02be395f",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.176034Z",
     "start_time": "2024-10-14T03:12:08.171871Z"
    }
   },
   "id": "917c26bc02be395f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "La clase **CatsDogsDataset** es una implementación personalizada de una clase llamda *Dataset* de PyTorch que permite cargar y transformar las imágenes del dataset.\n",
    "\n",
    "**Explicación**\n",
    "1. Constructor (\\_\\_init\\_\\_):  \n",
    "- img_path_list: Lista de rutas de las imágenes.\n",
    "- lab_list: Lista de etiquetas correspondientes a las imágenes (0 para gatos, 1 para perros).\n",
    "- transform: Transformaciones opcionales que se aplicarán a las imágenes (por ejemplo, redimensionar, normalizar).\n",
    "2. Método \\_\\_len\\_\\_:  \n",
    "- Devuelve la cantidad de imágenes en el conjunto de datos.\n",
    "3. Método \\_\\_getitem\\_\\_:\n",
    "- idx: Índice de la imagen y etiqueta que se desea obtener.\n",
    "- img_path: Obtiene la ruta de la imagen en el índice idx.\n",
    "- image: Abre la imagen y la convierte a formato RGB.\n",
    "- label: Obtiene la etiqueta correspondiente a la imagen y la convierte a un tensor de PyTorch.\n",
    "- Si se especificaron transformaciones, se aplican a la imagen.\n",
    "- Devuelve la imagen transformada y su etiqueta correspondiente."
   ],
   "metadata": {
    "id": "c-1bZ5CU3Gri"
   },
   "id": "c-1bZ5CU3Gri"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CatsDogsDataset(Dataset):\n",
    "    def __init__(self, img_path_list, lab_list, transform=None):\n",
    "        self.transform = transform\n",
    "        self.images = img_path_list\n",
    "        self.labels = lab_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        label = torch.Tensor([label])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "id": "2cd7f71cfa333705",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.179174Z",
     "start_time": "2024-10-14T03:12:08.176810Z"
    }
   },
   "id": "2cd7f71cfa333705",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definimos la resolución de las imágenes que serán procesadas."
   ],
   "metadata": {
    "id": "mNXY7zTh31QJ"
   },
   "id": "mNXY7zTh31QJ"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_size = (224,224)\n",
    "exp_config['input_size'] = input_size"
   ],
   "metadata": {
    "id": "61b41a6d728d3c10",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.181177Z",
     "start_time": "2024-10-14T03:12:08.179728Z"
    }
   },
   "id": "61b41a6d728d3c10",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como las imágenes son a color en formato RGB, definiremos 3 canales"
   ],
   "metadata": {
    "id": "fBTkFhnn382u"
   },
   "id": "fBTkFhnn382u"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_channels = 3\n",
    "exp_config['n_channels'] = n_channels"
   ],
   "metadata": {
    "id": "7e9634b1fc3514d6",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.183057Z",
     "start_time": "2024-10-14T03:12:08.181795Z"
    }
   },
   "id": "7e9634b1fc3514d6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos el *transform* que será usado, el cual redimensiona las imágenes a la resolución dada."
   ],
   "metadata": {
    "id": "qb6wxASF4KHR"
   },
   "id": "qb6wxASF4KHR"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ],
   "metadata": {
    "id": "60979fd3aadf9c30",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.186747Z",
     "start_time": "2024-10-14T03:12:08.185260Z"
    }
   },
   "id": "60979fd3aadf9c30",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos los datasets de train, test y val."
   ],
   "metadata": {
    "id": "j-RUgCbO4Yg_"
   },
   "id": "j-RUgCbO4Yg_"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CatsDogsDataset(train_df['image_path'].tolist(), train_df['label'].tolist(), transform)\n",
    "test_dataset = CatsDogsDataset(test_df['image_path'].tolist(), test_df['label'].tolist(), transform)\n",
    "val_dataset = CatsDogsDataset(val_df['image_path'].tolist(), val_df['label'].tolist(), transform)"
   ],
   "metadata": {
    "id": "5adde669c2867e8d",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.189138Z",
     "start_time": "2024-10-14T03:12:08.187297Z"
    }
   },
   "id": "5adde669c2867e8d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos los *DataLoaders* de train, test y val, y definimos el tamaño de lote.\n",
    "\n",
    "**Aclaración:** el batch size de test es 1,los datos no serán mezclados por cada época y no se eliminarán datos para alcanzar el tamaño de lote establecido."
   ],
   "metadata": {
    "id": "CzsTv8jC4-Js"
   },
   "id": "CzsTv8jC4-Js"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "exp_config['batch_size'] = batch_size\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ],
   "metadata": {
    "id": "cc5bed8c2518e66c",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.191868Z",
     "start_time": "2024-10-14T03:12:08.189625Z"
    }
   },
   "id": "cc5bed8c2518e66c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## WandB"
   ],
   "metadata": {
    "id": "EIOjZvGA-7hH"
   },
   "id": "EIOjZvGA-7hH"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mintart-estudiantes\u001B[0m (\u001B[33mar-um\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"d567fa512c6502cc7986d8c90fd37c4f0969de0d\")"
   ],
   "metadata": {
    "id": "xdsh8Yex_rmJ",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.760973Z",
     "start_time": "2024-10-14T03:12:08.192413Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "32355bbe-d244-45e8-99aa-f6339a400734"
   },
   "id": "xdsh8Yex_rmJ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelos"
   ],
   "metadata": {
    "collapsed": false,
    "id": "FFrM1a1R94KL"
   },
   "id": "FFrM1a1R94KL"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.conv1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.pool(x)\n",
    "\n",
    "      x = self.conv2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.pool(x)\n",
    "\n",
    "      x = self.flatten(x)\n",
    "      x = self.fc1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.fc2(x)\n",
    "      x = torch.sigmoid(x)\n",
    "\n",
    "      return x"
   ],
   "metadata": {
    "id": "JZ9_Zdd36fpA",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.767118Z",
     "start_time": "2024-10-14T03:12:08.762623Z"
    }
   },
   "id": "JZ9_Zdd36fpA",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "id": "8b08e7104cfe584d",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.770062Z",
     "start_time": "2024-10-14T03:12:08.767793Z"
    }
   },
   "id": "8b08e7104cfe584d",
   "execution_count": null
  },
  {
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AdvancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n"
   ],
   "cell_type": "code",
   "metadata": {
    "id": "7EDWNnbDg-NQ",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.774866Z",
     "start_time": "2024-10-14T03:12:08.770672Z"
    }
   },
   "id": "7EDWNnbDg-NQ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class InceptionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionCNN, self).__init__()\n",
    "        self.base_model = models.inception_v3(pretrained=True)\n",
    "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, 1)\n",
    "        self.base_model.aux_logits = False\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "id": "ab9ec139ba7bae95",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.780859Z",
     "start_time": "2024-10-14T03:12:08.777895Z"
    }
   },
   "execution_count": null,
   "id": "ab9ec139ba7bae95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definimos el dispositivo donde se realizará el entrenamiento (CPU o GPU)."
   ],
   "metadata": {
    "collapsed": false,
    "id": "a38be0e94c61dc74"
   },
   "id": "a38be0e94c61dc74"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ],
   "metadata": {
    "id": "a50750bcf13f5bf7",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.784795Z",
     "start_time": "2024-10-14T03:12:08.781750Z"
    }
   },
   "id": "a50750bcf13f5bf7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Función de entrenamiento y validación."
   ],
   "metadata": {
    "id": "LFqvj0Hz-fXq"
   },
   "id": "LFqvj0Hz-fXq"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, criterion, optimizer, device):\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_dataloader:\n",
    "        print(f\" SHAPE: {images.shape}\")\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        threshold = 0.5\n",
    "        predicted = (outputs.detach() >= threshold)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_avg_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    return train_avg_loss, train_accuracy\n",
    "\n",
    "def validate(model, val_dataloader, criterion, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            threshold = 0.5\n",
    "            predicted = (outputs.detach() >= threshold)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_avg_loss = running_loss / len(val_dataloader)\n",
    "    val_accuracy = correct / total\n",
    "\n",
    "    return val_avg_loss, val_accuracy\n",
    "\n",
    "def train_and_validate(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path):\n",
    "\n",
    "    best_val_loss = 5\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(model, train_dataloader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy = validate(model, val_dataloader, criterion, device)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}, '\n",
    "              f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "        wandb.log({\"epochs\": epoch,\n",
    "                  \"train_acc\": train_accuracy,\n",
    "                   \"train_loss\": train_loss,\n",
    "                   \"val_acc\": val_accuracy,\n",
    "                   \"val_loss\": val_loss})\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "          best_val_loss = val_loss\n",
    "          torch.save(model.state_dict(), checkpoint_path)\n",
    "          epochs_without_improvement = 0\n",
    "          print(\"Checkpoint saved\")\n",
    "\n",
    "        else:\n",
    "          epochs_without_improvement +=1\n",
    "          if epochs_without_improvement == early_stopping_patience:\n",
    "            print(\"Early Stopping\")\n",
    "            break"
   ],
   "metadata": {
    "id": "C7hXPmvE-kMD",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.790074Z",
     "start_time": "2024-10-14T03:12:08.785457Z"
    }
   },
   "id": "C7hXPmvE-kMD",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funcion de testeo"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3e31540877765f5"
   },
   "id": "3e31540877765f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(model, test_dataloader, device):\n",
    "    y_true = []\n",
    "    y_proba = []\n",
    "\n",
    "    for image, label in test_dataloader:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "\n",
    "            y_true.append(label.to(\"cpu\").float())\n",
    "            y_proba.append(output.to(\"cpu\").float())\n",
    "\n",
    "    return y_true, y_proba"
   ],
   "metadata": {
    "id": "b09e8dcc750244fb",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.792856Z",
     "start_time": "2024-10-14T03:12:08.790800Z"
    }
   },
   "id": "b09e8dcc750244fb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funcion para clasificar en base a un umbral"
   ],
   "metadata": {
    "collapsed": false,
    "id": "430399933d47ef8"
   },
   "id": "430399933d47ef8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def classify(y_proba, y_true, thr=0.5):\n",
    "\n",
    "    y_true_tensor = torch.cat(y_true)\n",
    "    y_proba_tensor = torch.cat(y_proba)\n",
    "\n",
    "    y_pred_tensor = (y_proba_tensor >= thr).int()\n",
    "\n",
    "    y_true = y_true_tensor.numpy()\n",
    "    y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "    y_proba_flat = y_proba_tensor.numpy().ravel()\n",
    "\n",
    "    return y_true, y_pred, y_proba_flat"
   ],
   "metadata": {
    "id": "761694971df87da5",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.795418Z",
     "start_time": "2024-10-14T03:12:08.793453Z"
    }
   },
   "id": "761694971df87da5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funcion para calcular metricas"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3559eeb984e98a3b"
   },
   "id": "3559eeb984e98a3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, precision_score, recall_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_proba_flat):\n",
    "    # Asegúrate de que `y_proba_flat` sea de la forma (n_samples,) si es binario\n",
    "    if len(y_proba_flat.shape) == 3:\n",
    "        # Si `y_proba_flat` tiene 3 dimensiones, selecciona solo una clase\n",
    "        y_proba_flat = y_proba_flat[:, :, 1].flatten()  # Probabilidades de la clase positiva\n",
    "\n",
    "    # Calcular las métricas\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "    # Calcular ROC y AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba_flat)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Logging con wandb\n",
    "    roc_data = [[x, y] for (x, y) in zip(fpr, tpr)]\n",
    "    table = wandb.Table(data=roc_data, columns=[\"FPR\", \"TPR\"])\n",
    "    wandb.log({\n",
    "        \"test_accuracy\": accuracy,\n",
    "        \"test_precision\": precision,\n",
    "        \"test_recall\": recall,\n",
    "        \"test_specificity\": specificity,\n",
    "        \"test_confusion_matrix\": wandb.plot.confusion_matrix(y_true=y_true.flatten().tolist(), preds=y_pred.flatten().tolist(), class_names=[\"Clase 0\", \"Clase 1\"]),\n",
    "        \"ROC Curve\": wandb.plot.line(table, \"FPR\", \"TPR\", title=\"ROC Curve\"),\n",
    "        \"test_roc_auc\": roc_auc,\n",
    "    })\n",
    "\n",
    "    return accuracy, precision, recall, specificity, conf_matrix, fpr, tpr, roc_auc\n"
   ],
   "metadata": {
    "id": "4dcf3e40a4d19ae4",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.798620Z",
     "start_time": "2024-10-14T03:12:08.796093Z"
    }
   },
   "id": "4dcf3e40a4d19ae4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Uso de los CNNs"
   ],
   "metadata": {
    "collapsed": false,
    "id": "deab16e8e1c742a1"
   },
   "id": "deab16e8e1c742a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SimpleCNN"
   ],
   "metadata": {
    "collapsed": false,
    "id": "a5ccc5191154960e"
   },
   "id": "a5ccc5191154960e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Elección de modelo, función de costo y optimizador."
   ],
   "metadata": {
    "id": "xXc3QO35-Gt0"
   },
   "id": "xXc3QO35-Gt0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241014_185408-wtqghrh2</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/wtqghrh2' target=\"_blank\">Bertoldi_Mancuso_SimpleCNN</a></strong> to <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/wtqghrh2' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/wtqghrh2</a>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "exp_config_SimpleCNN = exp_config.copy()\n",
    "\n",
    "wandb.init(project=\"CNN_CatsvsDogs\", entity=\"ar-um\", tags=[\"BERTOLDI_MANCUSO\"], name=\"Bertoldi_Mancuso_SimpleCNN\")\n",
    "wandb.config.update(exp_config_SimpleCNN)\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "exp_config_SimpleCNN['model'] = 'SimpleCNN'\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "exp_config_SimpleCNN['model'] = 'BCELoss'\n",
    "\n",
    "lr = 0.001\n",
    "exp_config_SimpleCNN['learning_rate'] = lr\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "exp_config_SimpleCNN['optimizador'] = 'Adam'"
   ],
   "metadata": {
    "id": "VjEFHNvs-Mvh",
    "ExecuteTime": {
     "end_time": "2024-10-14T03:13:39.603266Z",
     "start_time": "2024-10-14T03:12:08.799148Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "outputId": "bfbcda04-e344-4609-911c-f3989519154e"
   },
   "id": "VjEFHNvs-Mvh",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ajuste del modelo"
   ],
   "metadata": {
    "id": "V7EN1hNM-vUA"
   },
   "id": "V7EN1hNM-vUA"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aqui definimos la cantidad de epocas y el criterio que va a tener en cuenta para detener el entrenamiento en caso de no ver mejoras."
   ],
   "metadata": {
    "collapsed": false,
    "id": "de67d6fcea172d9e"
   },
   "id": "de67d6fcea172d9e"
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 15\n",
    "early_stopping_patience = 5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "exp_config_SimpleCNN['num_epochs'] = num_epochs\n",
    "exp_config_SimpleCNN['early_stopping_patience'] = early_stopping_patience\n",
    "\n",
    "checkpoint_path = './best_model.pth'\n",
    "\n",
    "train_and_validate(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path)"
   ],
   "metadata": {
    "id": "WuTBZ-ZU-x_a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c31b9d9e-694c-437c-edf4-746a6b891b42"
   },
   "id": "WuTBZ-ZU-x_a",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/15], Train Loss: 0.6445, Train Accuracy: 0.64, Validation Loss: 0.5844, Validation Accuracy: 0.70\n",
      "Checkpoint saved\n",
      "Epoch [2/15], Train Loss: 0.5454, Train Accuracy: 0.72, Validation Loss: 0.4650, Validation Accuracy: 0.79\n",
      "Checkpoint saved\n",
      "Epoch [3/15], Train Loss: 0.4578, Train Accuracy: 0.78, Validation Loss: 0.3526, Validation Accuracy: 0.85\n",
      "Checkpoint saved\n",
      "Epoch [4/15], Train Loss: 0.3482, Train Accuracy: 0.84, Validation Loss: 0.2426, Validation Accuracy: 0.92\n",
      "Checkpoint saved\n",
      "Epoch [5/15], Train Loss: 0.2355, Train Accuracy: 0.90, Validation Loss: 0.1422, Validation Accuracy: 0.96\n",
      "Checkpoint saved\n",
      "Epoch [6/15], Train Loss: 0.1171, Train Accuracy: 0.96, Validation Loss: 0.0571, Validation Accuracy: 0.99\n",
      "Checkpoint saved\n",
      "Epoch [7/15], Train Loss: 0.0581, Train Accuracy: 0.98, Validation Loss: 0.0236, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [8/15], Train Loss: 0.0207, Train Accuracy: 1.00, Validation Loss: 0.0078, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [9/15], Train Loss: 0.0091, Train Accuracy: 1.00, Validation Loss: 0.0071, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [10/15], Train Loss: 0.0039, Train Accuracy: 1.00, Validation Loss: 0.0013, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [11/15], Train Loss: 0.0009, Train Accuracy: 1.00, Validation Loss: 0.0005, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [12/15], Train Loss: 0.0005, Train Accuracy: 1.00, Validation Loss: 0.0003, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [13/15], Train Loss: 0.0003, Train Accuracy: 1.00, Validation Loss: 0.0002, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [14/15], Train Loss: 0.0002, Train Accuracy: 1.00, Validation Loss: 0.0002, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [15/15], Train Loss: 0.0002, Train Accuracy: 1.00, Validation Loss: 0.0001, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testeo"
   ],
   "metadata": {
    "id": "s-i41uMIBX3Y"
   },
   "id": "s-i41uMIBX3Y"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cargamos los parametros del modelo desde el checkpoint."
   ],
   "metadata": {
    "collapsed": false,
    "id": "e2762f34556a84"
   },
   "id": "e2762f34556a84"
  },
  {
   "cell_type": "code",
   "source": [
    "model = SimpleCNN().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "id": "lWdHrwGE-0QP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a6cc8c99-2319-4842-f831-3b642ec123ca"
   },
   "id": "lWdHrwGE-0QP",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-43-49698494f47b>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=100352, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hacemos predicciones en el conjunto de test."
   ],
   "metadata": {
    "collapsed": false,
    "id": "22a053c0281bfb34"
   },
   "id": "22a053c0281bfb34"
  },
  {
   "cell_type": "code",
   "source": [
    "y_true, y_proba = test(model, test_dataloader, device)"
   ],
   "metadata": {
    "id": "D6iOBHPNBcYt"
   },
   "id": "D6iOBHPNBcYt",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pasamos las predicciones a tensores y clasificamos en base a un umbral."
   ],
   "metadata": {
    "collapsed": false,
    "id": "2994a50623ffadb2"
   },
   "id": "2994a50623ffadb2"
  },
  {
   "cell_type": "code",
   "source": [
    "y_true, y_pred, y_proba_flat = classify(y_proba, y_true)"
   ],
   "metadata": {
    "id": "7OUK486cBhx9"
   },
   "id": "7OUK486cBhx9",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Métricas"
   ],
   "metadata": {
    "collapsed": false,
    "id": "8cc5965400f647c7"
   },
   "id": "8cc5965400f647c7"
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy, precision, recall, specificity, conf_matrix, fpr, tpr, roc_auc = calculate_metrics(y_true, y_pred, y_proba_flat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ],
   "metadata": {
    "id": "r2Bm6XvEBi6I",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bc8f2a1d-85d4-4fdf-a8cd-d11614316ff3"
   },
   "id": "r2Bm6XvEBi6I",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.96\n",
      "Precision: 0.96\n",
      "Recall: 0.96\n",
      "Specificity: 0.96\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'test_size': 0.15,\n",
       " 'val_size': 0.2,\n",
       " 'train_n_cats': 7984,\n",
       " 'train_n_dogs': 7934,\n",
       " 'val_n_cats': 1996,\n",
       " 'val_n_dogs': 1984,\n",
       " 'test_n_cats': 1761,\n",
       " 'test_n_dogs': 1751,\n",
       " 'input_size': (224, 224),\n",
       " 'n_channels': 3,\n",
       " 'batch_size': 64,\n",
       " 'model': 'BCELoss',\n",
       " 'learning_rate': 0.001,\n",
       " 'optimizador': 'Adam',\n",
       " 'num_epochs': 15,\n",
       " 'early_stopping_patience': 5}"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "exp_config_SimpleCNN"
   ],
   "metadata": {
    "id": "4fbc4186d25380e0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7e226059-be40-4e5f-e33e-cc7f17818f2d"
   },
   "id": "4fbc4186d25380e0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet18"
   ],
   "metadata": {
    "collapsed": false,
    "id": "d60bce6a14c24be5"
   },
   "id": "d60bce6a14c24be5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Elección de modelo, función de costo y optimizador."
   ],
   "metadata": {
    "collapsed": false,
    "id": "b09517aa11b8f9d4"
   },
   "id": "b09517aa11b8f9d4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:wtqghrh2) before initializing another..."
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.015 MB of 0.015 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e3071e8ea904846964d018eab0e86f1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▇█████████</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▆▇██████████</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>14</td></tr><tr><td>train_acc</td><td>1</td></tr><tr><td>train_loss</td><td>0.00018</td></tr><tr><td>val_acc</td><td>1</td></tr><tr><td>val_loss</td><td>0.00014</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Bertoldi_Mancuso_SimpleCNN</strong> at: <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/wtqghrh2' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/wtqghrh2</a><br/> View project at: <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20241014_185408-wtqghrh2/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:wtqghrh2). Initializing new run:<br/>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241014_193304-dvxcmxqr</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/dvxcmxqr' target=\"_blank\">Bertoldi_Mancuso_ResNet18CNN</a></strong> to <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/dvxcmxqr' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/dvxcmxqr</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 215MB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "exp_config_ResNet18 = exp_config.copy()\n",
    "\n",
    "wandb.init(project=\"CNN_CatsvsDogs\", entity=\"ar-um\", tags=[\"BERTOLDI_MANCUSO\"], name=\"Bertoldi_Mancuso_ResNet18CNN\")\n",
    "wandb.config.update(exp_config_ResNet18)\n",
    "\n",
    "model = ResNet18().to(device)\n",
    "exp_config_ResNet18['model'] = 'ResNet18'\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "exp_config_ResNet18['model'] = 'BCELoss'\n",
    "\n",
    "lr = 0.001\n",
    "exp_config_ResNet18['learning_rate'] = lr\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "exp_config_ResNet18['optimizador'] = 'Adam'\n",
    "\n",
    "model"
   ],
   "metadata": {
    "id": "dd1d07f97a7a2ebf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9e3071e8ea904846964d018eab0e86f1",
      "bbc769cb31424b1e8da897b3099f1dfb",
      "5476b33855e24e77922dd1b9f92b2748",
      "b4c2aa69bd584dec8b7774f753d49812",
      "a4dc9890ebad4cca8e9d48d72c1677e1",
      "10ef05e6b391417aa12903ae5f977a1c",
      "30f8afd4bca94b98a47c8934b3d70c41",
      "e280dcac892c4ff6ba552c7243e26c20"
     ]
    },
    "outputId": "7ce33eff-1a4c-4a55-e009-ae648d48f6c7"
   },
   "id": "dd1d07f97a7a2ebf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ajuste"
   ],
   "metadata": {
    "collapsed": false,
    "id": "2999cce4c3cf6adf"
   },
   "id": "2999cce4c3cf6adf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/15], Train Loss: 0.1445, Train Accuracy: 0.94, Validation Loss: 0.1016, Validation Accuracy: 0.96\n",
      "Checkpoint saved\n",
      "Epoch [2/15], Train Loss: 0.0843, Train Accuracy: 0.97, Validation Loss: 0.1421, Validation Accuracy: 0.95\n",
      "Epoch [3/15], Train Loss: 0.0712, Train Accuracy: 0.97, Validation Loss: 0.0601, Validation Accuracy: 0.98\n",
      "Checkpoint saved\n",
      "Epoch [4/15], Train Loss: 0.0565, Train Accuracy: 0.98, Validation Loss: 0.0502, Validation Accuracy: 0.98\n",
      "Checkpoint saved\n",
      "Epoch [5/15], Train Loss: 0.0465, Train Accuracy: 0.98, Validation Loss: 0.0425, Validation Accuracy: 0.98\n",
      "Checkpoint saved\n",
      "Epoch [6/15], Train Loss: 0.0339, Train Accuracy: 0.99, Validation Loss: 0.0288, Validation Accuracy: 0.99\n",
      "Checkpoint saved\n",
      "Epoch [7/15], Train Loss: 0.0346, Train Accuracy: 0.99, Validation Loss: 0.0444, Validation Accuracy: 0.98\n",
      "Epoch [8/15], Train Loss: 0.0313, Train Accuracy: 0.99, Validation Loss: 0.0375, Validation Accuracy: 0.99\n",
      "Epoch [9/15], Train Loss: 0.0285, Train Accuracy: 0.99, Validation Loss: 0.0368, Validation Accuracy: 0.99\n",
      "Epoch [10/15], Train Loss: 0.0242, Train Accuracy: 0.99, Validation Loss: 0.0220, Validation Accuracy: 0.99\n",
      "Checkpoint saved\n",
      "Epoch [11/15], Train Loss: 0.0226, Train Accuracy: 0.99, Validation Loss: 0.0291, Validation Accuracy: 0.99\n",
      "Epoch [12/15], Train Loss: 0.0201, Train Accuracy: 0.99, Validation Loss: 0.0134, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n",
      "Epoch [13/15], Train Loss: 0.0294, Train Accuracy: 0.99, Validation Loss: 0.0368, Validation Accuracy: 0.99\n",
      "Epoch [14/15], Train Loss: 0.0180, Train Accuracy: 0.99, Validation Loss: 0.0158, Validation Accuracy: 1.00\n",
      "Epoch [15/15], Train Loss: 0.0131, Train Accuracy: 1.00, Validation Loss: 0.0069, Validation Accuracy: 1.00\n",
      "Checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "early_stopping_patience = 5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "exp_config_ResNet18['num_epochs'] = num_epochs\n",
    "exp_config_ResNet18['early_stopping_patience'] = early_stopping_patience\n",
    "\n",
    "checkpoint_path = './best_model_ResNet18.pth'\n",
    "\n",
    "train_and_validate(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path)"
   ],
   "metadata": {
    "id": "5076c0f43c48a36",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f9622902-679d-4e96-896b-c7601f91fee4"
   },
   "id": "5076c0f43c48a36",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false,
    "id": "20c7e7a15183a253"
   },
   "id": "20c7e7a15183a253"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-50-a531f6f612b0>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "model = ResNet18().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "id": "cd0a6fbd12495d19",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5e768b62-5a68-417e-81ba-eb87764eb768"
   },
   "id": "cd0a6fbd12495d19",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_proba = test(model, test_dataloader, device)"
   ],
   "metadata": {
    "id": "cf3a31b31da431ad"
   },
   "id": "cf3a31b31da431ad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_pred, y_proba_flat = classify(y_proba, y_true)"
   ],
   "metadata": {
    "id": "ef4b7ee3bbe5db2c"
   },
   "id": "ef4b7ee3bbe5db2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.96\n",
      "Precision: 0.96\n",
      "Recall: 0.96\n",
      "Specificity: 0.96\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, specificity, conf_matrix, fpr, tpr, roc_auc = calculate_metrics(y_true, y_pred, y_proba_flat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ],
   "metadata": {
    "id": "531ec74d30dcb2a3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cbc88bcc-e08b-4b0e-ccf0-8519e68eee03"
   },
   "id": "531ec74d30dcb2a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'test_size': 0.15,\n",
       " 'val_size': 0.2,\n",
       " 'train_n_cats': 7984,\n",
       " 'train_n_dogs': 7934,\n",
       " 'val_n_cats': 1996,\n",
       " 'val_n_dogs': 1984,\n",
       " 'test_n_cats': 1761,\n",
       " 'test_n_dogs': 1751,\n",
       " 'input_size': (224, 224),\n",
       " 'n_channels': 3,\n",
       " 'batch_size': 64,\n",
       " 'model': 'BCELoss',\n",
       " 'learning_rate': 0.001,\n",
       " 'optimizador': 'Adam',\n",
       " 'num_epochs': 15,\n",
       " 'early_stopping_patience': 5}"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "exp_config_ResNet18"
   ],
   "metadata": {
    "id": "85865e115ba16b64",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d68c4643-28af-4a0d-9d9d-504c6f15d170"
   },
   "id": "85865e115ba16b64",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet 18 Modificado"
   ],
   "metadata": {
    "collapsed": false,
    "id": "8e747e4c92c04dfa"
   },
   "id": "8e747e4c92c04dfa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Elección de modelo, función de costo y optimizador."
   ],
   "metadata": {
    "collapsed": false,
    "id": "754a84af737d21c7"
   },
   "id": "754a84af737d21c7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:dvxcmxqr) before initializing another..."
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.015 MB of 0.015 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84ec112a9c174c939fe250a9083543b0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▇▇▇▇██▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>val_acc</td><td>▃▁▅▆▆▇▆▆▆▇▇█▆██</td></tr><tr><td>val_loss</td><td>▆█▄▃▃▂▃▃▃▂▂▁▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>14</td></tr><tr><td>train_acc</td><td>0.99546</td></tr><tr><td>train_loss</td><td>0.01306</td></tr><tr><td>val_acc</td><td>0.99842</td></tr><tr><td>val_loss</td><td>0.0069</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Bertoldi_Mancuso_ResNet18CNN</strong> at: <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/dvxcmxqr' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/dvxcmxqr</a><br/> View project at: <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20241014_193304-dvxcmxqr/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:dvxcmxqr). Initializing new run:<br/>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241014_203013-wlf3sz59</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/wlf3sz59' target=\"_blank\">Bertoldi_Mancuso_ResNet18ModificadoCNN</a></strong> to <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/wlf3sz59' target=\"_blank\">https://wandb.ai/ar-um/CNN_CatsvsDogs/runs/wlf3sz59</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "exp_config_ResNet18Modificado = exp_config.copy()\n",
    "\n",
    "wandb.init(project=\"CNN_CatsvsDogs\", entity=\"ar-um\", tags=[\"BERTOLDI_MANCUSO\"], name=\"Bertoldi_Mancuso_ResNet18ModificadoCNN\")\n",
    "wandb.config.update(exp_config_ResNet18Modificado)\n",
    "\n",
    "model = ResNet18().to(device)\n",
    "exp_config_ResNet18Modificado['model'] = 'ResNet18Modificado'\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "exp_config_ResNet18Modificado['model'] = 'BCELoss'\n",
    "\n",
    "lr = 0.001\n",
    "exp_config_ResNet18Modificado['learning_rate'] = lr\n",
    "\n",
    "# Se usara otro optimizador\n",
    "\n",
    "weight_decay = 0.01\n",
    "exp_config_ResNet18Modificado['weight_decay'] = weight_decay\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "exp_config_ResNet18Modificado['optimizador'] = 'AdamW'\n",
    "\n",
    "model"
   ],
   "metadata": {
    "id": "b0746d3371d2c65e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "84ec112a9c174c939fe250a9083543b0",
      "935b83a955cb42d19579e03f491dfb45",
      "8d2b17835b5b4d77a1f5e0215876cc96",
      "bbfd635ae8ac423bb97797d9c8b7e141",
      "d84db8e96a6842b3b8f5ae48317ebd44",
      "3d8bac83363c442ab0a1e5fbddb27a3b",
      "2dddd4cd31ad4ee99ba8e8bc569b5505",
      "17cc6ec5102849ccadf9d5fb8ab68e1f"
     ]
    },
    "outputId": "d7022ee4-9fc6-48c9-98a2-765c0a907ad6"
   },
   "id": "b0746d3371d2c65e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ajuste"
   ],
   "metadata": {
    "collapsed": false,
    "id": "dc644ecaa3e5fae4"
   },
   "id": "dc644ecaa3e5fae4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/15], Train Loss: 0.1396, Train Accuracy: 0.94, Validation Loss: 0.1470, Validation Accuracy: 0.94\n",
      "Checkpoint saved\n",
      "Epoch [2/15], Train Loss: 0.0896, Train Accuracy: 0.96, Validation Loss: 0.1232, Validation Accuracy: 0.95\n",
      "Checkpoint saved\n",
      "Epoch [3/15], Train Loss: 0.0715, Train Accuracy: 0.97, Validation Loss: 0.0981, Validation Accuracy: 0.96\n",
      "Checkpoint saved\n",
      "Epoch [4/15], Train Loss: 0.0597, Train Accuracy: 0.98, Validation Loss: 0.0355, Validation Accuracy: 0.99\n",
      "Checkpoint saved\n",
      "Epoch [5/15], Train Loss: 0.0441, Train Accuracy: 0.98, Validation Loss: 0.0384, Validation Accuracy: 0.99\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-60-3a481dbffed4>\u001B[0m in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mcheckpoint_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'./best_model_ResNet18.pth'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mtrain_and_validate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mearly_stopping_patience\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-37-32219474997b>\u001B[0m in \u001B[0;36mtrain_and_validate\u001B[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m         \u001B[0mtrain_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_accuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m         \u001B[0mval_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_accuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-37-32219474997b>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(model, train_dataloader, criterion, optimizer, device)\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m         \u001B[0mrunning_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0mthreshold\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "early_stopping_patience = 5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "exp_config_ResNet18Modificado['num_epochs'] = num_epochs\n",
    "exp_config_ResNet18Modificado['early_stopping_patience'] = early_stopping_patience\n",
    "\n",
    "checkpoint_path = './best_model_ResNet18.pth'\n",
    "\n",
    "train_and_validate(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path)"
   ],
   "metadata": {
    "id": "f5e7ac13a45d964c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "outputId": "5be040f9-b621-47f0-8997-571cc1ee2160"
   },
   "id": "f5e7ac13a45d964c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false,
    "id": "9a0a99e401ae94fd"
   },
   "id": "9a0a99e401ae94fd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-61-a531f6f612b0>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "model = ResNet18().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "id": "81f391a6bf403a68",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1c668599-11f9-4adf-acfb-b563454edfeb"
   },
   "id": "81f391a6bf403a68",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_proba = test(model, test_dataloader, device)"
   ],
   "metadata": {
    "id": "e3e7d677fdb04142"
   },
   "id": "e3e7d677fdb04142",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_pred, y_proba_flat = classify(y_proba, y_true)"
   ],
   "metadata": {
    "id": "bf9b71f5259eb20d"
   },
   "id": "bf9b71f5259eb20d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-70-daf4c48c79ff>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0maccuracy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprecision\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecall\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspecificity\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconf_matrix\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfpr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtpr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mroc_auc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalculate_metrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_proba_flat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Accuracy: {accuracy:.2f}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Precision: {precision:.2f}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Recall: {recall:.2f}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-69-6e279398fd45>\u001B[0m in \u001B[0;36mcalculate_metrics\u001B[0;34m(y_true, y_pred, y_proba_flat)\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0mspecificity\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrecall_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpos_label\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m     \u001B[0mfpr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtpr\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;34m=\u001B[0m \u001B[0mroc_curve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_proba\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# y_proba es la probabilidad predicha\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m     \u001B[0mroc_auc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mauc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfpr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtpr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    211\u001B[0m                     )\n\u001B[1;32m    212\u001B[0m                 ):\n\u001B[0;32m--> 213\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    214\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mInvalidParameterError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    215\u001B[0m                 \u001B[0;31m# When the function is just a wrapper around an estimator, we allow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001B[0m in \u001B[0;36mroc_curve\u001B[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001B[0m\n\u001B[1;32m   1143\u001B[0m     \u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m \u001B[0minf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.8\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0;36m0.4\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0;36m0.35\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.1\u001B[0m \u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1144\u001B[0m     \"\"\"\n\u001B[0;32m-> 1145\u001B[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001B[0m\u001B[1;32m   1146\u001B[0m         \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_score\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpos_label\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpos_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1147\u001B[0m     )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001B[0m in \u001B[0;36m_binary_clf_curve\u001B[0;34m(y_true, y_score, pos_label, sample_weight)\u001B[0m\n\u001B[1;32m    819\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_score\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    820\u001B[0m     \u001B[0my_true\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcolumn_or_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 821\u001B[0;31m     \u001B[0my_score\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcolumn_or_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_score\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    822\u001B[0m     \u001B[0massert_all_finite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    823\u001B[0m     \u001B[0massert_all_finite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_score\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcolumn_or_1d\u001B[0;34m(y, dtype, warn)\u001B[0m\n\u001B[1;32m   1379\u001B[0m     \"\"\"\n\u001B[1;32m   1380\u001B[0m     \u001B[0mxp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_namespace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1381\u001B[0;31m     y = check_array(\n\u001B[0m\u001B[1;32m   1382\u001B[0m         \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1383\u001B[0m         \u001B[0mensure_2d\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m   1056\u001B[0m             )\n\u001B[1;32m   1057\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mallow_nd\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1058\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m   1059\u001B[0m                 \u001B[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1060\u001B[0m                 \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mestimator_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, specificity, conf_matrix, fpr, tpr, roc_auc = calculate_metrics(y_true, y_pred, y_proba_flat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ],
   "metadata": {
    "id": "37105a9566bb12e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "outputId": "a1144cf0-944e-4526-e899-b58cdfc20cbc"
   },
   "id": "37105a9566bb12e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exp_config_ResNet18Modificado"
   ],
   "metadata": {
    "id": "bbf2a57837ecaee5"
   },
   "id": "bbf2a57837ecaee5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AdvancedCNN"
   ],
   "metadata": {
    "collapsed": false,
    "id": "345abf7483b2b9ce"
   },
   "id": "345abf7483b2b9ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Elección de modelo, función de costo y optimizador."
   ],
   "metadata": {
    "collapsed": false,
    "id": "70aa42eb1aa182ea"
   },
   "id": "70aa42eb1aa182ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "exp_config_AdvancedCNN = exp_config.copy()\n",
    "\n",
    "wandb.init(project=\"CNN_CatsvsDogs\", entity=\"ar-um\", tags=[\"BERTOLDI_MANCUSO\"], name=\"Bertoldi_Mancuso_AdvancedCNN\")\n",
    "wandb.config.update(exp_config_AdvancedCNN)\n",
    "\n",
    "model = AdvancedCNN().to(device)\n",
    "exp_config_AdvancedCNN['model'] = 'AdvancedCNN'\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "exp_config_AdvancedCNN['model'] = 'BCELoss'\n",
    "\n",
    "lr = 0.001\n",
    "exp_config_AdvancedCNN['learning_rate'] = lr\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "exp_config_AdvancedCNN['optimizador'] = 'Adam'\n",
    "\n",
    "model"
   ],
   "metadata": {
    "id": "e286d84afdd398d0"
   },
   "id": "e286d84afdd398d0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ajuste"
   ],
   "metadata": {
    "collapsed": false,
    "id": "fc8c41c09e6392db"
   },
   "id": "fc8c41c09e6392db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "early_stopping_patience = 5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "exp_config_AdvancedCNN['num_epochs'] = num_epochs\n",
    "exp_config_AdvancedCNN['early_stopping_patience'] = early_stopping_patience\n",
    "\n",
    "checkpoint_path = './best_model_AdvancedCNN.pth'\n",
    "\n",
    "train_and_validate(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path)"
   ],
   "metadata": {
    "id": "f462b1b48422bc83"
   },
   "id": "f462b1b48422bc83",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false,
    "id": "4f3e6325730805ba"
   },
   "id": "4f3e6325730805ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = AdvancedCNN().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "id": "b6af521514502a2b"
   },
   "id": "b6af521514502a2b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hacemos predicciones en el conjunto de test."
   ],
   "metadata": {
    "collapsed": false,
    "id": "9de1a51d71952b69"
   },
   "id": "9de1a51d71952b69"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_proba = test(model, test_dataloader, device)"
   ],
   "metadata": {
    "id": "65dcd595dfdaeac1"
   },
   "id": "65dcd595dfdaeac1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_pred, y_proba_flat = classify(y_proba, y_true)"
   ],
   "metadata": {
    "id": "4bcd90765b27f731"
   },
   "id": "4bcd90765b27f731",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accuracy, precision, recall, specificity, conf_matrix, fpr, tpr, roc_auc = calculate_metrics(y_true, y_pred, y_proba_flat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ],
   "metadata": {
    "id": "d277c3eaf83d0be1"
   },
   "id": "d277c3eaf83d0be1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exp_config_AdvancedCNN"
   ],
   "metadata": {
    "id": "20a239d95a63c130"
   },
   "id": "20a239d95a63c130",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## InceptionCNN"
   ],
   "metadata": {
    "collapsed": false,
    "id": "70b0e1855091aa65"
   },
   "id": "70b0e1855091aa65"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_size = (400,400)\n",
    "exp_config['input_size'] = input_size"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.181177Z",
     "start_time": "2024-10-14T03:12:08.179728Z"
    },
    "id": "kEeXDL_e5P0r"
   },
   "execution_count": null,
   "id": "kEeXDL_e5P0r"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como las imágenes son a color en formato RGB, definiremos 3 canales"
   ],
   "metadata": {
    "id": "0UYEcX_c5P0r"
   },
   "id": "0UYEcX_c5P0r"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_channels = 3\n",
    "exp_config['n_channels'] = n_channels"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.183057Z",
     "start_time": "2024-10-14T03:12:08.181795Z"
    },
    "id": "0RI3rJq05P0s"
   },
   "execution_count": null,
   "id": "0RI3rJq05P0s"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos el *transform* que será usado, el cual redimensiona las imágenes a la resolución dada."
   ],
   "metadata": {
    "id": "Sj49S6e15P0s"
   },
   "id": "Sj49S6e15P0s"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalización estándar para Inception v3\n",
    "\n",
    "])"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.186747Z",
     "start_time": "2024-10-14T03:12:08.185260Z"
    },
    "id": "uobk2bks5P0s"
   },
   "execution_count": null,
   "id": "uobk2bks5P0s"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos los datasets de train, test y val."
   ],
   "metadata": {
    "id": "-H9jRGQ65P0s"
   },
   "id": "-H9jRGQ65P0s"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CatsDogsDataset(train_df['image_path'].tolist(), train_df['label'].tolist(), transform)\n",
    "test_dataset = CatsDogsDataset(test_df['image_path'].tolist(), test_df['label'].tolist(), transform)\n",
    "val_dataset = CatsDogsDataset(val_df['image_path'].tolist(), val_df['label'].tolist(), transform)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.189138Z",
     "start_time": "2024-10-14T03:12:08.187297Z"
    },
    "id": "YndQBQdD5P0t"
   },
   "execution_count": null,
   "id": "YndQBQdD5P0t"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Elección de modelo, función de costo y optimizador."
   ],
   "metadata": {
    "collapsed": false,
    "id": "2279e3dcb430e838"
   },
   "id": "2279e3dcb430e838"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "exp_config['batch_size'] = batch_size\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T03:12:08.191868Z",
     "start_time": "2024-10-14T03:12:08.189625Z"
    },
    "id": "zINAhrLP5kO_"
   },
   "execution_count": null,
   "id": "zINAhrLP5kO_"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "error",
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 3.06 MiB is free. Process 9659 has 14.74 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 108.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-122-c20aee7ce642>\u001B[0m in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m#wandb.config.update(exp_config_Inception)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mInceptionCNN\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0mexp_config_Inception\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'InceptionCNN'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1172\u001B[0m                     \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1173\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1174\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1175\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1176\u001B[0m     def register_full_backward_pre_hook(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    778\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 780\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    778\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 780\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    778\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 780\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    778\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 780\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    803\u001B[0m             \u001B[0;31m# `with torch.no_grad():`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    804\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 805\u001B[0;31m                 \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    806\u001B[0m             \u001B[0mp_should_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    807\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1158\u001B[0m                         \u001B[0mmemory_format\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_to_format\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1159\u001B[0m                     )\n\u001B[0;32m-> 1160\u001B[0;31m                 return t.to(\n\u001B[0m\u001B[1;32m   1161\u001B[0m                     \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1162\u001B[0m                     \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 3.06 MiB is free. Process 9659 has 14.74 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 108.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "exp_config_Inception = exp_config.copy()\n",
    "\n",
    "#wandb.init(project=\"CNN_CatsvsDogs\", entity=\"ar-um\", tags=[\"BERTOLDI_MANCUSO\"], name=\"Bertoldi_Mancuso_InceptionCNN\")\n",
    "#wandb.config.update(exp_config_Inception)\n",
    "\n",
    "model = InceptionCNN().to(device)\n",
    "exp_config_Inception['model'] = 'InceptionCNN'\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "exp_config_Inception['model'] = 'BCELoss'\n",
    "\n",
    "lr = 0.001\n",
    "exp_config_Inception['learning_rate'] = lr\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "exp_config_Inception['optimizador'] = 'Adam'\n",
    "\n",
    "model"
   ],
   "metadata": {
    "id": "c73f0df0d2220ac2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "outputId": "45f9e490-c916-43b8-c1ec-cb0ca31cc236"
   },
   "id": "c73f0df0d2220ac2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ajuste"
   ],
   "metadata": {
    "collapsed": false,
    "id": "e5579e91605a4ea9"
   },
   "id": "e5579e91605a4ea9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " SHAPE: torch.Size([64, 3, 512, 512])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 9.06 MiB is free. Process 9659 has 14.74 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 51.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-116-ca02917029d3>\u001B[0m in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mcheckpoint_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'./best_model_InceptionCNN.pth'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mtrain_and_validate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mearly_stopping_patience\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-93-73fda0e2203f>\u001B[0m in \u001B[0;36mtrain_and_validate\u001B[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m         \u001B[0mtrain_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_accuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m         \u001B[0mval_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_accuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-93-73fda0e2203f>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(model, train_dataloader, criterion, optimizer, device)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compiled_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[misc]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1552\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1553\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1554\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1555\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1560\u001B[0m                 \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1561\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1563\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1564\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-101-1b8b0ce54c8b>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maux_logits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msigmoid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compiled_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[misc]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1552\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1553\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1554\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1555\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1560\u001B[0m                 \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1561\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1563\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1564\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/inception.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mInceptionOutputs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_transform_input\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    166\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maux\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m         \u001B[0maux_defined\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maux_logits\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/inception.py\u001B[0m in \u001B[0;36m_transform_input\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     96\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform_input\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m             \u001B[0mx_ch0\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.229\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.485\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m             \u001B[0mx_ch1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.224\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.456\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m             \u001B[0mx_ch2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.225\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.406\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_ch0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_ch1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_ch2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 9.06 MiB is free. Process 9659 has 14.74 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 51.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "early_stopping_patience = 5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "exp_config_Inception['num_epochs'] = num_epochs\n",
    "exp_config_Inception['early_stopping_patience'] = early_stopping_patience\n",
    "\n",
    "checkpoint_path = './best_model_InceptionCNN.pth'\n",
    "\n",
    "train_and_validate(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path)"
   ],
   "metadata": {
    "id": "33636581ed86202b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "outputId": "62367865-a366-44a8-c335-beea716263d4"
   },
   "id": "33636581ed86202b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false,
    "id": "f1059f86abf235cd"
   },
   "id": "f1059f86abf235cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = InceptionCNN().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "id": "2bb02c571f3b525b"
   },
   "id": "2bb02c571f3b525b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_proba = test(model, test_dataloader, device)"
   ],
   "metadata": {
    "id": "4ea448209096e7b1"
   },
   "id": "4ea448209096e7b1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_pred, y_proba_flat = classify(y_proba, y_true)"
   ],
   "metadata": {
    "id": "a5786e0c50d24a69"
   },
   "id": "a5786e0c50d24a69",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accuracy, precision, recall, specificity, conf_matrix, fpr, tpr, roc_auc = calculate_metrics(y_true, y_pred, y_proba_flat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ],
   "metadata": {
    "id": "5e9f6c85f5824bac"
   },
   "id": "5e9f6c85f5824bac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exp_config_Inception"
   ],
   "metadata": {
    "id": "9e2668c2c519175e"
   },
   "id": "9e2668c2c519175e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inception Modificado"
   ],
   "metadata": {
    "collapsed": false,
    "id": "189f456affd6af9f"
   },
   "id": "189f456affd6af9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Elección de modelo, función de costo y optimizador."
   ],
   "metadata": {
    "collapsed": false,
    "id": "16418645bb9b6abe"
   },
   "id": "16418645bb9b6abe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "exp_config_InceptionModificado = exp_config.copy()\n",
    "\n",
    "wandb.init(project=\"CNN_CatsvsDogs\", entity=\"ar-um\", tags=[\"BERTOLDI_MANCUSO\"], name=\"Bertoldi_Mancuso_InceptionModificadoCNN\")\n",
    "wandb.config.update(exp_config_InceptionModificado)\n",
    "\n",
    "model = InceptionCNN().to(device)\n",
    "exp_config_InceptionModificado['model'] = 'InceptionModificado'\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "exp_config_InceptionModificado['model'] = 'BCELoss'\n",
    "\n",
    "lr = 0.01\n",
    "exp_config_InceptionModificado['learning_rate'] = lr\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "exp_config_InceptionModificado['optimizador'] = 'Adam'\n",
    "\n",
    "model"
   ],
   "metadata": {
    "id": "4e50976ab1f4e34c"
   },
   "id": "4e50976ab1f4e34c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ajuste"
   ],
   "metadata": {
    "collapsed": false,
    "id": "1a04c2a9c64c2e89"
   },
   "id": "1a04c2a9c64c2e89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "early_stopping_patience = 5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "exp_config_InceptionModificado['num_epochs'] = num_epochs\n",
    "exp_config_InceptionModificado['early_stopping_patience'] = early_stopping_patience\n",
    "\n",
    "checkpoint_path = './best_model_Inception.pth'\n",
    "\n",
    "train_and_validate(model, train_dataloader, val_dataloader, criterion, optimizer, device, num_epochs, early_stopping_patience, checkpoint_path)"
   ],
   "metadata": {
    "id": "22eb1f0c71d83619"
   },
   "id": "22eb1f0c71d83619",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false,
    "id": "c645d0b0a0fbc365"
   },
   "id": "c645d0b0a0fbc365"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = InceptionCNN().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ],
   "metadata": {
    "id": "c9a10dc6d2301ad7"
   },
   "id": "c9a10dc6d2301ad7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_proba = test(model, test_dataloader, device)"
   ],
   "metadata": {
    "id": "bc1ff961b7aaddad"
   },
   "id": "bc1ff961b7aaddad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true, y_pred, y_proba_flat = classify(y_proba, y_true)"
   ],
   "metadata": {
    "id": "f9081a59ef29c414"
   },
   "id": "f9081a59ef29c414",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accuracy, precision, recall, specificity, conf_matrix, fpr, tpr, roc_auc = calculate_metrics(y_true, y_pred, y_proba_flat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ],
   "metadata": {
    "id": "e2f492b4a89e461c"
   },
   "id": "e2f492b4a89e461c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exp_config_InceptionModificado"
   ],
   "metadata": {
    "id": "485f79331964b633"
   },
   "id": "485f79331964b633",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "id": "ffc0f827378e91d7"
   },
   "id": "ffc0f827378e91d7",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "9e3071e8ea904846964d018eab0e86f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbc769cb31424b1e8da897b3099f1dfb",
       "IPY_MODEL_5476b33855e24e77922dd1b9f92b2748"
      ],
      "layout": "IPY_MODEL_b4c2aa69bd584dec8b7774f753d49812"
     }
    },
    "bbc769cb31424b1e8da897b3099f1dfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4dc9890ebad4cca8e9d48d72c1677e1",
      "placeholder": "​",
      "style": "IPY_MODEL_10ef05e6b391417aa12903ae5f977a1c",
      "value": "0.015 MB of 0.015 MB uploaded\r"
     }
    },
    "5476b33855e24e77922dd1b9f92b2748": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30f8afd4bca94b98a47c8934b3d70c41",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e280dcac892c4ff6ba552c7243e26c20",
      "value": 1
     }
    },
    "b4c2aa69bd584dec8b7774f753d49812": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4dc9890ebad4cca8e9d48d72c1677e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10ef05e6b391417aa12903ae5f977a1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30f8afd4bca94b98a47c8934b3d70c41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e280dcac892c4ff6ba552c7243e26c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "84ec112a9c174c939fe250a9083543b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_935b83a955cb42d19579e03f491dfb45",
       "IPY_MODEL_8d2b17835b5b4d77a1f5e0215876cc96"
      ],
      "layout": "IPY_MODEL_bbfd635ae8ac423bb97797d9c8b7e141"
     }
    },
    "935b83a955cb42d19579e03f491dfb45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d84db8e96a6842b3b8f5ae48317ebd44",
      "placeholder": "​",
      "style": "IPY_MODEL_3d8bac83363c442ab0a1e5fbddb27a3b",
      "value": "0.015 MB of 0.015 MB uploaded\r"
     }
    },
    "8d2b17835b5b4d77a1f5e0215876cc96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dddd4cd31ad4ee99ba8e8bc569b5505",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_17cc6ec5102849ccadf9d5fb8ab68e1f",
      "value": 1
     }
    },
    "bbfd635ae8ac423bb97797d9c8b7e141": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d84db8e96a6842b3b8f5ae48317ebd44": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d8bac83363c442ab0a1e5fbddb27a3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dddd4cd31ad4ee99ba8e8bc569b5505": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cc6ec5102849ccadf9d5fb8ab68e1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
